{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with importing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desummation import Desummation\n",
    "import numpy as np\n",
    "dsm = Desummation(frobenius=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new matrix\n",
    "$$\n",
    "    A = \\begin{pmatrix}\n",
    "    3 & 7 & 2 & 0 \\\\\n",
    "    -4 & 2 & 0 & -3 \\\\\n",
    "    5 & 0 & 2 & -1 \\\\\n",
    "    5 & -5 & -2 & -4 \\\\\n",
    "    \\end{pmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[3, 7, 2, 0], [-4, 2, 0, -3], [5, 0, 2, -1], [5, -5, -2, -4]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit some random matrices to this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the information you might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.5529813055313904,\n",
       " 2.047894123578386,\n",
       " 0.5549823445059108,\n",
       " 1.5380872470465992,\n",
       " 1.7219524754039952,\n",
       " -3.568307316109877,\n",
       " 0.7760269189016276,\n",
       " 0.26037605428385646]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see which matrix we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.25839512,  0.54932249,  4.67347974, -3.43624062],\n",
       "       [-2.63289042,  5.54635755, -3.21100934, -5.44207486],\n",
       "       [ 4.79544036,  4.62945317,  7.92624024,  0.03808044],\n",
       "       [ 4.86774898,  3.15865999, -5.87463203,  2.33751828]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.201746831190654"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not very good approximation.\n",
    "#### Certain ways to improve this:\n",
    "- ##### make more trials for weights searching (using weights_old.py)\n",
    "- ##### `make more random matrices`\n",
    "- ##### change metric between matrices\n",
    "- ##### change distribution of elements in matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 16, n_trials=2000, distribution='exponential', scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.49008778,  6.56725884,  1.30891383,  1.00222828],\n",
       "       [-4.48271286,  1.23232763,  0.43420658, -2.36250735],\n",
       "       [ 4.46386166,  0.5863807 ,  2.62649365, -0.27789372],\n",
       "       [ 4.44015546, -4.56082377, -1.64088647, -4.78427559]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4783407015143646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.064224537688366,\n",
       " 4.4988492662401125,\n",
       " -0.14695064132478652,\n",
       " -0.463633915141596,\n",
       " 2.085320259850917,\n",
       " -0.8863371560313302,\n",
       " -6.993807917023584,\n",
       " -2.0345938105140515,\n",
       " -0.22139692171349612,\n",
       " -1.0854576899648194,\n",
       " 1.5735516459468215,\n",
       " -0.3150599397742937,\n",
       " -3.314346089807451,\n",
       " 4.333272339612023,\n",
       " -1.9390516013540662,\n",
       " 0.44415057925499557]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the inferences?\n",
    "\n",
    "### You can experiment with it yourself, but judging by my intuition and my experiments:\n",
    "- Almost always we will find weights with (frobenius norm) loss close to 0 `if` we use the same amount of weights as we have total matrix elements (tested only for square matrix for now). I think that it may be some sort of `solution to a linear system`.\n",
    "\n",
    "\n",
    "- I thought a lot about applying this to ML and DL and came up to some insight: [you can see this page](https://weightagnostic.github.io/) or trust my words. The experiment showcased on this page focused on utilizing random weights in ANNs `without` any explicit `weight training`, but `rather allowing the weights between neuron connections to be learned`. This approach offers a more cost-effective training method while still achieving impressive capabilities. This just reminded me of my problem, no inference actually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's get some information about loss function for some fixed basis\n",
    "### Is it convex? For someone who already knows the answer, you can go just down below for an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, start with simple one:\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -1 \\\\\n",
    "-5 & 4 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "dsm_convexity2 = Desummation()\n",
    "A1 = [[2, -1], [-5, 4]]\n",
    "dsm_convexity2.fit(A1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now define a function for plotting\n",
    "- #### We will need a meshgrid of x and y.\n",
    "    - ##### I will be using only 2 random matrices for good visualization (x and y coordinates).\n",
    "    - ##### Weights are programmed to be found from $2 \\cdot min$ to $2 \\cdot max$ value of matrix A, but maybe this is wrong. I don't know it yet.\n",
    "- #### Also a function that will return an error, for that I will calculate the frobenius norm loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "w1 = np.linspace(-20, 20, n)\n",
    "w2 = np.linspace(-20, 20, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_loss(x, y, dsm_object, target, distance='fro'):\n",
    "    B = np.tensordot(np.stack([x, y]), dsm_object.matrices(), axes=1)\n",
    "    return np.linalg.norm(target - B, ord=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(w1, w2, Z):\n",
    "    fig = go.Figure(data=[go.Surface(x=w1, y=w2, z=Z)], layout=go.Layout(width=600, height=400))\n",
    "\n",
    "    # Set layout options\n",
    "    fig.update_layout(\n",
    "        title='3D Plot of Loss Function',\n",
    "        scene=dict(\n",
    "            xaxis_title='w1',\n",
    "            yaxis_title='w2',\n",
    "            zaxis_title='Loss',\n",
    "            aspectratio=dict(x=1, y=1, z=1),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1, y=1, z=1)\n",
    "            )\n",
    "        ),\n",
    "        autosize=True\n",
    "    )\n",
    "    argmin = np.argmin(Z)\n",
    "    row_index = argmin // n\n",
    "    col_index = argmin % n\n",
    "\n",
    "    print(f'Minimum value obtained at {np.min(Z)} with weights: w1:{w1[col_index]} and w2:{w2[row_index]}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity2, target=A1) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot1](picture/plot1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think it's a strike!!!\n",
    "#### It's `clearly convex` function! And only with 2 weights. Case was very simple, but you can modify values in A, call dsm_convexety.fit() again to update random matrices, see if anything changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try more difficult one:\n",
    "#### This time convexity is quite questionable\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -5 & 4 \\\\\n",
    "-3 & -3 & 2 \\\\\n",
    "1 & 2 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_convexity3 = Desummation()\n",
    "A2 = [[2, -5, 4], [-3, -3, 2], [1, 2, 6]]\n",
    "dsm_convexity3.fit(A2, 2, distribution = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "w1 = np.linspace(-12, 12, n)\n",
    "w2 = np.linspace(-12, 12, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity3, target=A2) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot2](picture/plot2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is convex too! You can try various shapes of A, various distributions, but there wouldn't be a case of not convex plot.\n",
    "#### This is all because of [convexity of frobenius norm](https://ics.uci.edu/~xhx/courses/ConvexOpt/convex_functions.pdf)!\n",
    "So we can just go with how many weights we want and will always find a best approximation for our matrix.\n",
    "## Now it's time to reveal the truth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is actually a *numerical solution*. And, as we already know, `distinct` which is due to convexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It took 20 seconds for matrix with shape (4, 4) and with 16 random matrices to find a solution, which can still appear to be not the best one.\n",
    "#### Now let me solve it in <0.1 second with brilliant accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  7  2  0]\n",
      " [-4  2  0 -3]\n",
      " [ 5  0  2 -1]\n",
      " [ 5 -5 -2 -4]]\n",
      "[[ 3.00000000e+00  7.00000000e+00  2.00000000e+00  1.28785871e-14]\n",
      " [-4.00000000e+00  2.00000000e+00 -1.15463195e-14 -3.00000000e+00]\n",
      " [ 5.00000000e+00  2.88657986e-15  2.00000000e+00 -1.00000000e+00]\n",
      " [ 5.00000000e+00 -5.00000000e+00 -2.00000000e+00 -4.00000000e+00]]\n",
      "[ 0.97247319 -6.24826884  0.53365514 -3.47484654  0.38267372  0.27795969\n",
      " -6.12543311  4.76471103  4.70331179 -0.09877375 -2.0538444  -3.26253404\n",
      " -1.92325275  2.72239096 -0.32218645  1.67457795]\n",
      "3.754918050587562e-14\n"
     ]
    }
   ],
   "source": [
    "A = [[3, 7, 2, 0], [-4, 2, 0, -3], [5, 0, 2, -1], [5, -5, -2, -4]] \n",
    "dsm_new = Desummation(frobenius=True)\n",
    "print(np.array(A), dsm_new.fit_predict(A, 16), dsm_new.weights(), dsm_new.error(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now it works with frobenius norm between matrices and maybe there is closer in some metric.\n",
    "### But when amount is equals to a number of elements in matrix it finds the best approximation possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why this works:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll explain it in the case of 3x3 matrix, but all stays the same for any shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (*Definition*)\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "p_1 & p_2 & p_3 \\\\\n",
    "p_4 & p_5 & p_6 \\\\\n",
    "p_7 & p_8 & p_9 \\\\\n",
    "\\end{pmatrix}_{3 \\times 3} = w_1 \\cdot \\begin{pmatrix}\n",
    "a^1_{11} & a^1_{12} & a^1_{13} \\\\\n",
    "a^1_{21} & a^1_{22} & a^1_{23} \\\\\n",
    "a^1_{31} & a^1_{32} & a^1_{33} \\\\\n",
    "\\end{pmatrix}_{3 \\times 3}+ \\ldots + w_k \\cdot \\begin{pmatrix}\n",
    "a^k_{11} & a^k_{12} & a^k_{13} \\\\\n",
    "a^k_{21} & a^k_{22} & a^k_{23} \\\\\n",
    "a^k_{31} & a^k_{32} & a^k_{33} \\\\\n",
    "\\end{pmatrix}_{3 \\times 3}\n",
    "$$\n",
    "### This is equivalent to this *system of linear equations*:\n",
    "$$\n",
    "w_1 \\cdot a^1_{11} + w_2 \\cdot a^2_{11} + \\ldots + w_k \\cdot a^k_{11} = p_1 \\\n",
    "$$\n",
    "$$\n",
    "\\vdots\n",
    "$$\n",
    "$$\n",
    "w_1 \\cdot a^1_{33} + w_2 \\cdot a^2_{33} + \\ldots + w_k \\cdot a^k_{33} = p_9\n",
    "$$\n",
    "- ##### *9* equations (n $\\cdot$ m in general case)\n",
    "- ##### *k* weights\n",
    "- ##### System is *overdefined*\n",
    "    - ##### There is already a solution: [you can check this Wikipedia page with explicit answer for overdefined systems](https://en.wikipedia.org/wiki/Overdetermined_system#Approximate_solutions)\n",
    "    - ##### This solution is `least squares method`\n",
    "    - ##### And for k = n $\\cdot$ m there is the best possible numerical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For an application to MNIST digits dataset you may now check Part 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
