{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with importing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Саша Кукунцев\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from desummation import Desummation\n",
    "import numpy as np\n",
    "dsm = Desummation(frobenius=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new matrix\n",
    "$$\n",
    "    A = \\begin{pmatrix}\n",
    "    3 & 7 & 2 & 0 \\\\\n",
    "    -4 & 2 & 0 & -3 \\\\\n",
    "    5 & 0 & 2 & -1 \\\\\n",
    "    5 & -5 & -2 & -4 \\\\\n",
    "    \\end{pmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[3, 7, 2, 0], [-4, 2, 0, -3], [5, 0, 2, -1], [5, -5, -2, -4]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit some random matrices to this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the information you might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9959145757334049,\n",
       " 1.7353229119542704,\n",
       " -1.769175760841783,\n",
       " -0.951925874629227,\n",
       " -0.6389510768087661,\n",
       " -0.6481928622120527,\n",
       " 0.335578504420174,\n",
       " 0.08559811370613435]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see which matrix we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.22676272,  4.59115912,  1.33574653,  3.09838367],\n",
       "       [-1.15288095, -3.09817721,  2.89299121,  1.53051538],\n",
       "       [-0.17945724,  0.16412803,  0.75920111, -2.9419244 ],\n",
       "       [ 1.25150493, -2.13508865, -0.95119253, -0.45168037]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.93763348874473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not very good approximation.\n",
    "#### Certain ways to improve this:\n",
    "- ##### make more trials for weights searching (using weights_old.py)\n",
    "- ##### `make more random matrices`\n",
    "- ##### change metric between matrices\n",
    "- ##### change distribution of elements in matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 16, n_trials=2000, distribution='exponential', scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.49008778,  6.56725884,  1.30891383,  1.00222828],\n",
       "       [-4.48271286,  1.23232763,  0.43420658, -2.36250735],\n",
       "       [ 4.46386166,  0.5863807 ,  2.62649365, -0.27789372],\n",
       "       [ 4.44015546, -4.56082377, -1.64088647, -4.78427559]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4783407015143646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.064224537688366,\n",
       " 4.4988492662401125,\n",
       " -0.14695064132478652,\n",
       " -0.463633915141596,\n",
       " 2.085320259850917,\n",
       " -0.8863371560313302,\n",
       " -6.993807917023584,\n",
       " -2.0345938105140515,\n",
       " -0.22139692171349612,\n",
       " -1.0854576899648194,\n",
       " 1.5735516459468215,\n",
       " -0.3150599397742937,\n",
       " -3.314346089807451,\n",
       " 4.333272339612023,\n",
       " -1.9390516013540662,\n",
       " 0.44415057925499557]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the inferences?\n",
    "\n",
    "### You can experiment with it yourself, but judging by my intuition and my experiments:\n",
    "- #### Almost always we will find weights with (frobenius norm) loss close to 0 `if` we use $n^2$ weights (tested only for square matrix for now). I think that it may be some sort of `solution to a linear system`. You may understand me beforehand if you remember the basis for matrices(the one consisting of $E_{ij}$ matrices)\n",
    "- #### I think a lot about applying this to ML and DL and came up to some insight: [you can see this page](https://weightagnostic.github.io/) or trust my words. The experiment showcased on this page focused on utilizing random weights in ANNs `without` any explicit `weight training`, but `rather allowing the weights between neuron connections to be learned`. This approach offers a more cost-effective training method while still achieving impressive capabilities. This just reminds me of my problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's get some information about loss function for some fixed basis\n",
    "### Is it convex? For someone who already knows the answer, you can go just down below for an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, start with simple one:\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -1 \\\\\n",
    "-5 & 4 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "dsm_convexity2 = Desummation()\n",
    "A1 = [[2, -1], [-5, 4]]\n",
    "dsm_convexity2.fit(A1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now define a function for plotting\n",
    "- #### We will need a meshgrid of x and y.\n",
    "    - ##### I will be using only 2 random matrices for good visualization (x and y coordinates).\n",
    "    - ##### Weights are programmed to be found from $2 \\cdot min$ to $2 \\cdot max$ value of matrix A, but maybe this is wrong. I don't know it yet.\n",
    "- #### Also a function that will return an error, for that I will calculate the frobenius norm loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "w1 = np.linspace(-20, 20, n)\n",
    "w2 = np.linspace(-20, 20, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_loss(x, y, dsm_object, target, distance='fro'):\n",
    "    B = np.tensordot(np.stack([x, y]), dsm_object.matrices(), axes=1)\n",
    "    return np.linalg.norm(target - B, ord=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(w1, w2, Z):\n",
    "    fig = go.Figure(data=[go.Surface(x=w1, y=w2, z=Z)], layout=go.Layout(width=600, height=400))\n",
    "\n",
    "    # Set layout options\n",
    "    fig.update_layout(\n",
    "        title='3D Plot of Loss Function',\n",
    "        scene=dict(\n",
    "            xaxis_title='w1',\n",
    "            yaxis_title='w2',\n",
    "            zaxis_title='Loss',\n",
    "            aspectratio=dict(x=1, y=1, z=1),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1, y=1, z=1)\n",
    "            )\n",
    "        ),\n",
    "        autosize=True\n",
    "    )\n",
    "    argmin = np.argmin(Z)\n",
    "    row_index = argmin // n\n",
    "    col_index = argmin % n\n",
    "\n",
    "    print(f'Minimum value obtained at {np.min(Z)} with weights: w1:{w1[col_index]} and w2:{w2[row_index]}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity2, target=A1) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot1](plot1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think it's a strike!!!\n",
    "#### It's `clearly convex` function! And only with 2 weights. Case was very simple, but you can modify values in A, call dsm_convexety.fit() again to update random matrices, see if anything changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try more difficult one:\n",
    "#### This time convexity is quite questionable\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -5 & 4 \\\\\n",
    "-3 & -3 & 2 \\\\\n",
    "1 & 2 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_convexity3 = Desummation()\n",
    "A2 = [[2, -5, 4], [-3, -3, 2], [1, 2, 6]]\n",
    "dsm_convexity3.fit(A2, 2, distribution = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "w1 = np.linspace(-12, 12, n)\n",
    "w2 = np.linspace(-12, 12, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity3, target=A2) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot2](plot2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is convex too! You can try various shapes of A, various distributions, but there wouldn't be a case of not convex plot.\n",
    "#### This is all because of [convexity of frobenius norm](https://ics.uci.edu/~xhx/courses/ConvexOpt/convex_functions.pdf)!\n",
    "So we can just go with how many weights we want and will always find a best approximation for our matrix.\n",
    "## Now it's time to reveal the truth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is actually a *numerical solution*. And, as we already know, `distinct` which is due to convexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It took 20 seconds for matrix with shape (4, 4) and with 16 random matrices to find a solution, which can still appear to be not the best one.\n",
    "#### Now let me solve it in <0.1 second with brilliant accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  7  2  0]\n",
      " [-4  2  0 -3]\n",
      " [ 5  0  2 -1]\n",
      " [ 5 -5 -2 -4]]\n",
      "[[ 3.00000000e+00  7.00000000e+00  2.00000000e+00  1.28785871e-14]\n",
      " [-4.00000000e+00  2.00000000e+00 -1.15463195e-14 -3.00000000e+00]\n",
      " [ 5.00000000e+00  2.88657986e-15  2.00000000e+00 -1.00000000e+00]\n",
      " [ 5.00000000e+00 -5.00000000e+00 -2.00000000e+00 -4.00000000e+00]]\n",
      "[ 0.97247319 -6.24826884  0.53365514 -3.47484654  0.38267372  0.27795969\n",
      " -6.12543311  4.76471103  4.70331179 -0.09877375 -2.0538444  -3.26253404\n",
      " -1.92325275  2.72239096 -0.32218645  1.67457795]\n",
      "3.754918050587562e-14\n"
     ]
    }
   ],
   "source": [
    "A = [[3, 7, 2, 0], [-4, 2, 0, -3], [5, 0, 2, -1], [5, -5, -2, -4]] \n",
    "dsm_new = Desummation(frobenius=True)\n",
    "print(np.array(A), dsm_new.fit_predict(A, 16), dsm_new.weights(), dsm_new.error(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For now it works with frobenius norm between matrices and maybe there is closer in some metric.\n",
    "### But when amount is equals to a number of elements in matrix it finds the best approximation possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why this works:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll explain it in the case of 3x3 matrix, but all stays the same for any shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (*Definition*)\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "p_1 & p_2 & p_3 \\\\\n",
    "p_4 & p_5 & p_6 \\\\\n",
    "p_7 & p_8 & p_9 \\\\\n",
    "\\end{pmatrix}_{3 \\times 3} = w_1 \\cdot \\begin{pmatrix}\n",
    "a^1_{11} & a^1_{12} & a^1_{13} \\\\\n",
    "a^1_{21} & a^1_{22} & a^1_{23} \\\\\n",
    "a^1_{31} & a^1_{32} & a^1_{33} \\\\\n",
    "\\end{pmatrix}_{3 \\times 3}+ \\ldots + w_k \\cdot \\begin{pmatrix}\n",
    "a^k_{11} & a^k_{12} & a^k_{13} \\\\\n",
    "a^k_{21} & a^k_{22} & a^k_{23} \\\\\n",
    "a^k_{31} & a^k_{32} & a^k_{33} \\\\\n",
    "\\end{pmatrix}_{3 \\times 3}\n",
    "$$\n",
    "### This is equivalent to this *system of linear equations*:\n",
    "$$\n",
    "w_1 \\cdot a^1_{11} + w_2 \\cdot a^2_{11} + \\ldots + w_k \\cdot a^k_{11} = p_1 \\\n",
    "$$\n",
    "$$\n",
    "\\vdots\n",
    "$$\n",
    "$$\n",
    "w_1 \\cdot a^1_{33} + w_2 \\cdot a^2_{33} + \\ldots + w_k \\cdot a^k_{33} = p_9\n",
    "$$\n",
    "- ##### *9* equations (n $\\cdot$ m in general case)\n",
    "- ##### *k* weights\n",
    "- ##### System is *overdefined*\n",
    "    - ##### There is already a solution: [you can check this Wikipedia page with explicit answer for overdefined systems](https://en.wikipedia.org/wiki/Overdetermined_system#Approximate_solutions)\n",
    "    - ##### This solution is `least squares method`\n",
    "    - ##### And for k = n $\\cdot$ m there is the best possible solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now this code becomes really fast and I will certainly try to implement it later in the future. `Stay tuned for updates!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes = list(np.where(np.array(train_labels) == 0)[0][:800])\n",
    "ones = list(np.where(np.array(train_labels) == 1)[0][:800])\n",
    "twos = list(np.where(np.array(train_labels) == 2)[0][1:800])\n",
    "threes = list(np.where(np.array(train_labels) == 3)[0][1:800])\n",
    "fours = list(np.where(np.array(train_labels) == 4)[0][1:800])\n",
    "fives = list(np.where(np.array(train_labels) == 5)[0][1:800])\n",
    "sixs = list(np.where(np.array(train_labels) == 6)[0][1:800])\n",
    "sevens = list(np.where(np.array(train_labels) == 7)[0][1:800])\n",
    "eights = list(np.where(np.array(train_labels) == 8)[0][1:800])\n",
    "nines = list(np.where(np.array(train_labels) == 9)[0][1:800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_pictures = Desummation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = rd.randint(40000, 50000)\n",
    "label = train_labels[index]\n",
    "example = np.resize(train_images[index], (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01880452 -0.2215909   0.06647508  0.10929012 -0.05060546 -0.05560098\n",
      "  0.32165179  0.0403623  -0.16179138 -0.02652222  0.09073106 -0.0848242\n",
      "  0.0508344  -0.05162291  0.30457355  0.03279023  0.03553536  0.1487288\n",
      "  0.10051966 -0.04084005  0.00184897 -0.04654179  0.08949025 -0.29858415\n",
      " -0.01929603 -0.12235003 -0.01857105  0.16578686  0.01506455 -0.03286886\n",
      "  0.00314574 -0.05281984 -0.03037149  0.01779776  0.12675322  0.00964304\n",
      "  0.29375892  0.08640911  0.08950766  0.26367472  0.12014886  0.05357645\n",
      " -0.05022515 -0.15763315  0.02355312 -0.06600257  0.02868888 -0.06024196\n",
      " -0.05197705 -0.01954878 -0.05023972 -0.0655277  -0.0568371   0.02274273\n",
      " -0.06703567 -0.01674478  0.09889447  0.17808384  0.07776731  0.09451693\n",
      " -0.03704589 -0.16223943 -0.05858117 -0.07893769  0.07206404 -0.1705875\n",
      " -0.03234059 -0.24725974  0.06159277  0.09699763  0.06589414 -0.0908826\n",
      "  0.04447005 -0.0490828   0.11966788  0.03989903  0.04780069  0.18868159\n",
      "  0.18486928 -0.01381648 -0.00677635 -0.12491791  0.08292058  0.05540012\n",
      " -0.01985633 -0.1068507  -0.07162251  0.04894037  0.05216932  0.0195811\n",
      "  0.08664653  0.02309216  0.05940901  0.02718636  0.06782897 -0.01874787\n",
      "  0.19612888 -0.0413192  -0.19577975  0.29524886  0.04883217 -0.07623531\n",
      " -0.23932739  0.02384817 -0.23334407 -0.27302331 -0.11283416  0.02120211\n",
      " -0.0209608  -0.00693773  0.23334707 -0.0443423  -0.35384607  0.3359301\n",
      " -0.01059788 -0.01901775 -0.05667216 -0.01980098  0.16644739  0.09694054\n",
      " -0.01038139  0.00117847  0.05553103  0.02603661 -0.15871092  0.02843189\n",
      " -0.05578353 -0.08157052 -0.04021073 -0.07037681 -0.12404827  0.10374221\n",
      "  0.16732373  0.0616739   0.04021242  0.06285866 -0.11086814  0.03937654\n",
      " -0.05809852 -0.01381199  0.05587     0.02266684  0.03919346 -0.03744335\n",
      " -0.0224983   0.29388015  0.1573665  -0.13497197  0.09838403 -0.01563432\n",
      " -0.16000037  0.04052272  0.10719307  0.02572461  0.07753506 -0.05596094\n",
      " -0.05062461 -0.05088209 -0.06162234  0.0941283   0.02273221 -0.00401382\n",
      " -0.16052303 -0.00716074  0.00347555 -0.03720744 -0.03896372 -0.02281401\n",
      "  0.09638717  0.07314552  0.11657125 -0.09907282  0.0186494  -0.12878479\n",
      "  0.21656575  0.19738811 -0.02832159 -0.12236777  0.03187933 -0.02008568\n",
      " -0.01570269 -0.01468586 -0.08279351 -0.11515565 -0.05720196  0.00175488\n",
      " -0.08256941  0.08212059  0.05586557 -0.06435342  0.14813471 -0.1696414\n",
      " -0.20436498  0.02117222 -0.09520256 -0.12724584 -0.00410068  0.10106298\n",
      " -0.06387355  0.00816245] 511.07185996819993\n",
      "Answer 2\n",
      "Index 49314\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 200\n",
    "dsm_pictures.fit(example, dim)\n",
    "for j in range(dim):\n",
    "    dsm_pictures.basis.matrices[j] = np.resize(train_images[j], (28, 28))\n",
    "picture_one = dsm_pictures.predict(example)\n",
    "print(dsm_pictures.weights(), dsm_pictures.error())\n",
    "print(\"Answer\", label)\n",
    "print('Index', index)\n",
    "plt.imshow(picture_one, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
