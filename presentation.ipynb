{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with importing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desummation import Desummation\n",
    "import numpy as np\n",
    "dsm = Desummation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new matrix\n",
    "$$\n",
    "    A = \\begin{pmatrix}\n",
    "    3 & 7 & 2 & 0 \\\\\n",
    "    -4 & 2 & 0 & -3 \\\\\n",
    "    5 & 0 & 2 & -1 \\\\\n",
    "    5 & -5 & -2 & -4 \\\\\n",
    "    \\end{pmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[3, 7, 2, 0], [-4, 2, 0, -3], [5, 0, 2, -1], [5, -5, -2, -4]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit some random matrices to this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the information you might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.7921641252757965,\n",
       " 0.02856497634380073,\n",
       " 0.8271760431198532,\n",
       " 0.4419829614685806,\n",
       " 0.32373200244346556,\n",
       " -3.3607544209767717,\n",
       " -2.4707198383725855,\n",
       " 1.1102889503140112]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see which matrix we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.61432699,  5.40926024,  1.98908676,  3.15317878],\n",
       "       [-1.85441934,  4.47421948,  2.07227529, -0.47229592],\n",
       "       [-1.07867   ,  6.90137977,  0.60671286, -1.49416506],\n",
       "       [ 1.2140232 , -0.12356885, -2.25194497, -1.20161187]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.635929305053782"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not very good approximation.\n",
    "#### Certain ways to improve this:\n",
    "- ##### make more trials for weights searching\n",
    "- ##### make more random matrices\n",
    "- ##### change metric between matrices\n",
    "- ##### change distribution of elements in matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm.fit(A, 16, n_trials=2000, distribution='exponential', scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.49423493e+00,  7.03729570e+00,  1.52029639e+00,\n",
       "         2.89002971e-03],\n",
       "       [-4.82552532e+00,  2.56053925e+00, -2.54434113e-01,\n",
       "        -4.02818656e+00],\n",
       "       [ 5.33013779e+00,  7.46179565e-01,  2.69805038e+00,\n",
       "        -8.14147507e-01],\n",
       "       [ 3.61820494e+00, -4.10825540e+00, -2.27045590e+00,\n",
       "        -2.56621879e+00]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.predict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  7,  2,  0],\n",
       "       [-4,  2,  0, -3],\n",
       "       [ 5,  0,  2, -1],\n",
       "       [ 5, -5, -2, -4]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9934800562620194"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.7416757946297725,\n",
       " -2.7044970637199057,\n",
       " -6.476469954411555,\n",
       " 3.8006027499983297,\n",
       " 2.9322448688949017,\n",
       " 1.8536921265782187,\n",
       " 4.289883674097096,\n",
       " 0.32352551822984577,\n",
       " 0.2155499512293888,\n",
       " -2.880591723501701,\n",
       " -1.2933023480717178,\n",
       " -6.066299519204691,\n",
       " -0.888029899842083,\n",
       " -0.8156192990179143,\n",
       " 4.008491664386714,\n",
       " -0.02515789902350285]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm.weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the inferences?\n",
    "\n",
    "### You can experiment with it yourself, but judging by my intuition and my experiments:\n",
    "- #### Almost always we will find weights with (frobenius norm) loss close to 0 `if` we use $n^2$ weights (tested only for square matrix for now). I think that it may be some sort of `solution to a linear system`. You may understand me beforehand if you remember the basis for matrices(the one consisting of $E_{ij}$ matrices)\n",
    "- #### I think a lot about applying this to ML and DL and came up to some insight: [you can see this page](https://weightagnostic.github.io/) or trust my words. The experiment showcased on this page focused on utilizing random weights in ANNs `without` any explicit `weight training`, but `rather allowing the weights between neuron connections to be learned`. This approach offers a more cost-effective training method while still achieving impressive capabilities. This just reminds me of my problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's get some information about loss function for some fixed basis\n",
    "### Is it convex? For someone who already knows the answer, you can go just down below for an explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, start with simple one:\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -1 \\\\\n",
    "-5 & 4 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "dsm_convexity2 = Desummation()\n",
    "A1 = [[2, -1], [-5, 4]]\n",
    "dsm_convexity2.fit(A1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now define a function for plotting\n",
    "- #### We will need a meshgrid of x and y.\n",
    "    - ##### I will be using only 2 random matrices for good visualization (x and y coordinates).\n",
    "    - ##### Weights are programmed to be found from $2 \\cdot min$ to $2 \\cdot max$ value of matrix A, but maybe this is wrong. I don't know it yet.\n",
    "- #### Also a function that will return an error, for that I will calculate the frobenius norm loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "w1 = np.linspace(-20, 20, n)\n",
    "w2 = np.linspace(-20, 20, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_loss(x, y, dsm_object, target, distance='fro'):\n",
    "    B = np.tensordot(np.stack([x, y]), dsm_object.matrices(), axes=1)\n",
    "    return np.linalg.norm(target - B, ord=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(w1, w2, Z):\n",
    "    fig = go.Figure(data=[go.Surface(x=w1, y=w2, z=Z)], layout=go.Layout(width=600, height=400))\n",
    "\n",
    "    # Set layout options\n",
    "    fig.update_layout(\n",
    "        title='3D Plot of Loss Function',\n",
    "        scene=dict(\n",
    "            xaxis_title='w1',\n",
    "            yaxis_title='w2',\n",
    "            zaxis_title='Loss',\n",
    "            aspectratio=dict(x=1, y=1, z=1),\n",
    "            camera=dict(\n",
    "                eye=dict(x=1, y=1, z=1)\n",
    "            )\n",
    "        ),\n",
    "        autosize=True\n",
    "    )\n",
    "    argmin = np.argmin(Z)\n",
    "    row_index = argmin // n\n",
    "    col_index = argmin % n\n",
    "\n",
    "    print(f'Minimum value obtained at {np.min(Z)} with weights: w1:{w1[col_index]} and w2:{w2[row_index]}')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity2, target=A1) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot1](plot1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think it's a strike!!!\n",
    "#### It's `clearly convex` function! And only with 2 weights. Case was very simple, but you can modify values in A, call dsm_convexety.fit() again to update random matrices, see if anything changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try more difficult one:\n",
    "#### This time convexity is quite questionable\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "2 & -5 & 4 \\\\\n",
    "-3 & -3 & 2 \\\\\n",
    "1 & 2 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_convexity3 = Desummation()\n",
    "A2 = [[2, -5, 4], [-3, -3, 2], [1, 2, 6]]\n",
    "dsm_convexity3.fit(A2, 2, distribution = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "w1 = np.linspace(-12, 12, n)\n",
    "w2 = np.linspace(-12, 12, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[frobenius_loss(x=x, y=y, dsm_object=dsm_convexity3, target=A2) for x in w1] for y in w2])\n",
    "#plot(w1, w2, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot2](plot2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is convex too! You can try various shapes of A, various distributions, but there wouldn't be a case of not convex plot.\n",
    "#### This is all because of convexity of frobenius norm!\n",
    "So we can just go with how many weights we want and will always find a best approximation for our matrix.\n",
    "## Now it's time for further experiments... Stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
